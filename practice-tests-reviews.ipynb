{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Engineering \n",
    "| Kinesis Firehose |\n",
    "|:- |\n",
    "|La conversión a parquet es desde json, si es csv se debe usar una Lambda para convertir a json previamente.|\n",
    "\n",
    ". The normalization transformer normalizes numeric variables to have a mean of zero and variance of one. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling\n",
    "\n",
    "## IF-IDF \n",
    "\n",
    "Vector dimension:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#!pip install sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\"Don't stop believing in yourself\", \"Don't quit on yourself now\"]\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "print(x.shape)\n",
    "print (vectorizer.get_feature_names())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 16)\n",
      "['believing', 'believing in', 'don', 'don quit', 'don stop', 'in', 'in yourself', 'now', 'on', 'on yourself', 'quit', 'quit on', 'stop', 'stop believing', 'yourself', 'yourself now']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Exploratory Data Analysis\n",
    "| Notas |\n",
    "|:- |\n",
    "|Pearson Correlation coefficient para ver features altamente correlacionados (no las elimina)|\n",
    "|Data augmentation en imágenes se puede hacer con flip, cambiar la tonalidad, zoom.|\n",
    "|The Multiple Imputations by Chained Equations (MICE) algorithm is a robust, informative method of dealing with missing data in your datasets. This procedure imputes or 'fills in' the missing data in a dataset through an iterative series of predictive models. Each specified variable in the dataset is imputed in each iteration using the other variables in the dataset.|"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Machine Learning Implementation and Operations\n",
    "\n",
    "| Notas |\n",
    "|:- |\n",
    "|Polly tiene la posibilidad de custom lexicons y vocabularios|\n",
    "|containers deben ser nvidia-docker compatible e incluir cuda toolkit en los contenedores para aprovechar la GPU (no se deben instalar drivers) |\n",
    "\n",
    "- Data Formats https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n",
    "\n",
    "- En un entrenamiento distribuido es posible establecer inter-container traffic encryption.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Overfitting UnderFitting\n",
    "| Overfitting | UnderFitting\n",
    "|:- |:-\n",
    "|Modelo funciona bien en la data de train pero mal en test|Modelo No puede capturar la relacion entre los ejemplos y el target\n",
    "|Modelo memorizó la data y no generaliza datos no vistos|Modelo es muy simple\n",
    "|Feature Selection: Menos features, decrementar n-gram . Aplicar Regularización|agregar mas features especificos del dominio, más complejidad (n-gram por ejemplo)\n",
    "\n",
    "Bajo accuracy en test y train se puede deber a falta de ejemplos:\n",
    "- Aumentar los datos\n",
    "- Aumentar los pasos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
  },
  "interpreter": {
   "hash": "bd79022972ec85884f8c7282d79e951f39671388dc60a8721cf30436bd2e415b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}